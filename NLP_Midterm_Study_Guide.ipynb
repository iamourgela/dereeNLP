{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4141b55a",
   "metadata": {},
   "source": [
    "# ðŸ§  NLP Midterm Study Notebook\n",
    "This guided notebook will help you review key concepts from preprocessing, embeddings, supervised learning, and LDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9015a217",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Section 1: Preprocessing\n",
    "Review how text is cleaned before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845def6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Clean the text using lowercase, remove URLs, usernames, and non-alphabet characters\n",
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \"<URL>\", text)\n",
    "    text = re.sub(r\"@\\w+\", \"<USER>\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)  # normalize repeated letters\n",
    "    return text\n",
    "\n",
    "# Try it out:\n",
    "sample_text = \"Sooo excited!!! Check this out: https://example.com @user123\"\n",
    "print(preprocess(sample_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdac54df",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Section 2: Embeddings\n",
    "Review sparse vs dense embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60703ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Compare TF-IDF and Word2Vec embeddings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\"I love machine learning\", \"Text data is very interesting\", \"I love working with NLP\"]\n",
    "\n",
    "# TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(corpus)\n",
    "print(\"TF-IDF shape:\", X_tfidf.shape)\n",
    "\n",
    "# Word2Vec (mock example)\n",
    "# In practice, use gensim.models.Word2Vec or pretrained embeddings\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "tokens = [sent.lower().split() for sent in corpus]\n",
    "w2v_model = Word2Vec(sentences=tokens, vector_size=50, window=3, min_count=1, workers=1)\n",
    "print(\"Word2Vec vector for 'love':\", w2v_model.wv['love'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6cdbd9",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Section 3: Supervised Learning\n",
    "Train models using vectorized text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9062fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Train a simple classifier on TF-IDF features\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y = [1, 0, 1]  # labels: 1 = positive, 0 = neutral\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20fe6f5",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Section 4: Topic Modeling with LDA\n",
    "Extract topics from documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbd52dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "# Tokenize and create dictionary\n",
    "tokenized_docs = [doc.lower().split() for doc in corpus]\n",
    "dictionary = Dictionary(tokenized_docs)\n",
    "corpus_bow = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "\n",
    "# LDA\n",
    "lda_model = LdaModel(corpus=corpus_bow, id2word=dictionary, num_topics=2, random_state=0)\n",
    "topics = lda_model.print_topics()\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
